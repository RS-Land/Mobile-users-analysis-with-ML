{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "\n",
    "We have access to behavior data about subscribers who have already switched to the new plans. For this classification task, we need to develop a model that will pick the right plan. \n",
    "\n",
    "Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from joblib import dump\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/datasets/users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['calls'] = df['calls'].astype('int16')\n",
    "df['messages'] = df['messages'].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>560.51</td>\n",
       "      <td>20</td>\n",
       "      <td>9619.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>344.32</td>\n",
       "      <td>13</td>\n",
       "      <td>19898.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>437.13</td>\n",
       "      <td>61</td>\n",
       "      <td>21523.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>433.07</td>\n",
       "      <td>16</td>\n",
       "      <td>16702.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>587.90</td>\n",
       "      <td>0</td>\n",
       "      <td>14406.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    calls  minutes  messages   mb_used  is_ultra\n",
       "0      40   311.90        83  19915.42         0\n",
       "1      85   516.75        56  22696.96         0\n",
       "2      77   467.66        86  21060.45         0\n",
       "3     106   745.53        81   8437.39         1\n",
       "4      66   418.74         1  14502.75         0\n",
       "5      58   344.56        21  15823.37         0\n",
       "6      57   431.64        20   3738.90         1\n",
       "7      15   132.40         6  21911.60         0\n",
       "8       7    43.39         3   2538.67         1\n",
       "9      90   665.41        38  17358.61         0\n",
       "10     82   560.51        20   9619.53         1\n",
       "11     45   344.32        13  19898.81         0\n",
       "12     51   437.13        61  21523.58         0\n",
       "13     56   433.07        16  16702.36         0\n",
       "14    108   587.90         0  14406.50         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the source data into sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is the set of the data on which the actual training takes place. Validation split helps to improve the model performance by fine-tuning the model after each epoch. The test set informs us about the final accuracy of the model after completing the training phase.\n",
    "\n",
    "The training set should not be too small; else, the model will not have enough data to learn. On the other hand, if the validation set is too small, then the evaluation metrics like accuracy and precision will have large variance and will not lead to the proper tuning of the model.\n",
    "\n",
    "In our case test set doesn't exist. Therefore the source data has to be split into three parts: training, validation, and test. The sizes of validation set and test set are usually equal. It gives us source data split in a 3:1:1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2571, 4)\n",
      "(2571,)\n",
      "(1928, 4)\n",
      "(1928,)\n",
      "(643, 4)\n",
      "(643,)\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say we want to split the data in 60:20:20 for train:valid:test dataset\n",
    "\n",
    "x = df.drop(columns = ['is_ultra']).copy()\n",
    "y = df['is_ultra']\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train2, x_test, y_train2, y_test = train_test_split(x,y, train_size=0.8,random_state=12345)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (20% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train2,y_train2, test_size=0.25,random_state=12345)\n",
    "\n",
    "print(x_train2.shape), print(y_train2.shape)\n",
    "print(x_train.shape), print(y_train.shape)\n",
    "print(x_valid.shape), print(y_valid.shape)\n",
    "print(x_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best combination of the hyperparameters:\n",
      "max_depth is 10\n",
      "criterion is entropy\n",
      "min_samples_leaf is 10\n",
      "min_samples_split is 10\n",
      "Accuracy is 0.7931570762052877\n"
     ]
    }
   ],
   "source": [
    "goal=0\n",
    "for i in range(1,11):\n",
    "    for min_samples_split in range(2,11):\n",
    "        for min_samples_leaf in range(1,11):\n",
    "            for criterion in ['gini', 'entropy']:\n",
    "                model_dt = DecisionTreeClassifier(random_state=12345, max_depth=i,criterion = criterion,\n",
    "                                               min_samples_split=min_samples_split,\n",
    "                                              min_samples_leaf=min_samples_leaf)\n",
    "                model_dt.fit(x_train, y_train)\n",
    "                predictions_dt = model_dt.predict(x_valid)\n",
    "                accuracy_dt = accuracy_score(y_valid, predictions_dt)\n",
    "                #print(i,criterion, \": \", end='')\n",
    "                #print(accuracy)\n",
    "    if accuracy_dt > goal:\n",
    "        goal= accuracy_dt\n",
    "        goal_max_depth=i\n",
    "        goal_criterion = criterion\n",
    "        goal_min_samples_leaf=min_samples_leaf\n",
    "        goal_min_samples_split=min_samples_split\n",
    "print('The best combination of the hyperparameters:')\n",
    "print(\"max_depth is\", goal_max_depth)\n",
    "print(\"criterion is\", goal_criterion)\n",
    "print(\"min_samples_leaf is\", goal_min_samples_leaf)\n",
    "print(\"min_samples_split is\", goal_min_samples_split)\n",
    "print(\"Accuracy is\",goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to choose which hyperparameters to adjust is by conducting an exhaustive grid search.\n",
    "\n",
    "An exhaustive grid search takes in as many hyperparameters as we would like, and tries every single possible combination of the hyperparameters as well as as many cross-validations as we would like it to perform. An exhaustive grid search is a good way to determine the best hyperparameter values to use, but it is time consuming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]\n",
    "#n_estimators =[]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,10]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 17, 25, 33, 41, 48, 56, 64, 72, 80], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 10], 'min_samples_split': [2, 10], 'min_samples_leaf': [1, 10], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 320 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 3200 out of 3200 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 25}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Model = RandomForestClassifier()\n",
    "rf_Grid = GridSearchCV(estimator = rf_Model, param_grid = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
    "rf_Grid.fit(x_train, y_train)\n",
    "rf_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy - : 0.896\n"
     ]
    }
   ],
   "source": [
    "print (f'Train Accuracy - : {rf_Grid.score(x_train,y_train):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7900466562986003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rf = rf_Grid.predict(x_valid)\n",
    "accuracy_rf = accuracy_score(y_valid, predictions_rf)\n",
    "accuracy_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is lower than expected: we were expecting to get accuracy higher than the one of the decision tree model.\n",
    "We will try to alter parameters ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = []\n",
    "best_accuracy = 0\n",
    "\n",
    "for n_estimators in (1,50):\n",
    "    for max_depth in range(2,10):\n",
    "        for min_samples_split in range(2,10):\n",
    "            for min_samples_leaf in range(1,8):\n",
    "                for criterion in ['gini', 'entropy']:\n",
    "                    \n",
    "                    model_rf_clf = RandomForestClassifier(random_state=123,\n",
    "                                                          n_estimators=n_estimators,\n",
    "                                                          max_depth=max_depth,\n",
    "                                                          min_samples_split=min_samples_split,\n",
    "                                                          min_samples_leaf=min_samples_leaf,\n",
    "                                                          criterion=criterion)\n",
    "                    \n",
    "                    model_rf_clf.fit(x_train, y_train)\n",
    "                    \n",
    "                    predictions = model_rf_clf.predict(x_valid)\n",
    "                    \n",
    "                    accuracy = accuracy_score(y_valid, predictions)\n",
    "                    \n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_params = [n_estimators, max_depth, min_samples_split, min_samples_leaf, criterion]\n",
    "                        best_accuracy = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79782\n",
      "The best combination of the hyperparameters for random forest classifier:\n",
      "   n_estimators = 50\n",
      "   max_depth = 9\n",
      "   min_samples_split = 2\n",
      "   min_samples_leaf = 4\n",
      "   criterion = gini \n"
     ]
    }
   ],
   "source": [
    "print('''Accuracy: {}\n",
    "The best combination of the hyperparameters for random forest classifier:\n",
    "   n_estimators = {}\n",
    "   max_depth = {}\n",
    "   min_samples_split = {}\n",
    "   min_samples_leaf = {}\n",
    "   criterion = {} '''.format(round(best_accuracy, 5),\n",
    "                             best_params[0],\n",
    "                             best_params[1],\n",
    "                             best_params[2],\n",
    "                             best_params[3],\n",
    "                             best_params[4]\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression does not really have any critical hyperparameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703838174273859\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=12345, solver='liblinear') \n",
    "model_lr.fit(x_train, y_train) \n",
    "print(model_lr.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6967340590979783"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr = model_lr.predict(x_valid)\n",
    "accuracy_lr= accuracy_score(y_valid, predictions_lr)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the lowest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've tested 3 common models: Decision Tree, Random Forest and Logistic Regression.\n",
    "\n",
    "Logistic Regression has the lowest accuracy.\n",
    "\n",
    "We will choose random forest model since it has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the quality of the model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7978227060653188"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=123, n_estimators=50,\n",
    "                               max_depth=9, min_samples_split=2,min_samples_leaf=4,\n",
    "                              max_features='auto',criterion = 'gini') \n",
    "model.fit(x_train, y_train) \n",
    "predictions = model.predict(x_test)\n",
    "accuracy= accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the chosen model using 80% of data and check it using the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8040435458786936"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=123, n_estimators=50,\n",
    "                               max_depth=9, min_samples_split=2,min_samples_leaf=4,\n",
    "                              max_features='auto',criterion = 'gini') \n",
    "model.fit(x_train2, y_train2) \n",
    "predictions = model.predict(x_test)\n",
    "accuracy= accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We managed to obtain the accuracy of the model to be 0.804.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sanity check we will compare our model to some simple baseline.\n",
    "\n",
    "For example, we can use a constant model that is built-in the sklearn library: sklearn.dummy.DummyClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6951788491446346"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(x_train2, y_train2)\n",
    "predictions_dummy=dummy_clf.predict(x_test)\n",
    "accuracy_dummy= accuracy_score(y_test, predictions_dummy)\n",
    "accuracy_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6951788491446346"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "dummy_clf.fit(x_train2, y_train2)\n",
    "predictions_dummy=dummy_clf.predict(x_test)\n",
    "accuracy_dummy= accuracy_score(y_test, predictions_dummy)\n",
    "accuracy_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5878693623639192"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(x_train2, y_train2)\n",
    "predictions_dummy=dummy_clf.predict(x_test)\n",
    "accuracy_dummy= accuracy_score(y_test, predictions_dummy)\n",
    "accuracy_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen model passed this sanity check. Our model has an accuracy significantly higher.\n",
    "\n",
    "The accuracy is 0.804."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1518,
    "start_time": "2022-02-28T18:52:25.344Z"
   },
   {
    "duration": 133,
    "start_time": "2022-02-28T18:53:51.675Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-28T18:55:00.020Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-28T18:55:25.173Z"
   },
   {
    "duration": 385,
    "start_time": "2022-02-28T18:56:20.698Z"
   },
   {
    "duration": 214,
    "start_time": "2022-02-28T18:56:27.625Z"
   },
   {
    "duration": 38,
    "start_time": "2022-02-28T18:56:35.183Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-28T18:56:55.029Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-28T18:57:01.766Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-28T19:03:26.417Z"
   },
   {
    "duration": 252,
    "start_time": "2022-02-28T19:21:16.059Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-28T19:21:25.922Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-28T19:50:00.388Z"
   },
   {
    "duration": 35,
    "start_time": "2022-02-28T19:50:10.503Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-28T19:50:14.137Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-28T20:12:20.941Z"
   },
   {
    "duration": 248,
    "start_time": "2022-02-28T20:13:29.103Z"
   },
   {
    "duration": 54,
    "start_time": "2022-02-28T20:13:36.211Z"
   },
   {
    "duration": 87,
    "start_time": "2022-02-28T20:13:55.189Z"
   },
   {
    "duration": 100,
    "start_time": "2022-02-28T20:15:03.296Z"
   },
   {
    "duration": 82,
    "start_time": "2022-02-28T20:28:17.026Z"
   },
   {
    "duration": 168,
    "start_time": "2022-02-28T20:39:12.197Z"
   },
   {
    "duration": 168,
    "start_time": "2022-02-28T20:39:19.690Z"
   },
   {
    "duration": 173,
    "start_time": "2022-02-28T20:39:31.200Z"
   },
   {
    "duration": 169,
    "start_time": "2022-02-28T20:40:25.251Z"
   },
   {
    "duration": 189,
    "start_time": "2022-02-28T20:41:02.572Z"
   },
   {
    "duration": 190,
    "start_time": "2022-02-28T20:43:13.490Z"
   },
   {
    "duration": 258,
    "start_time": "2022-02-28T20:50:17.988Z"
   },
   {
    "duration": 14978,
    "start_time": "2022-02-28T20:51:23.897Z"
   },
   {
    "duration": 75,
    "start_time": "2022-02-28T20:52:31.504Z"
   },
   {
    "duration": 15730,
    "start_time": "2022-02-28T20:52:46.773Z"
   },
   {
    "duration": 14585,
    "start_time": "2022-02-28T20:54:47.546Z"
   },
   {
    "duration": 14507,
    "start_time": "2022-02-28T20:56:33.194Z"
   },
   {
    "duration": 1069,
    "start_time": "2022-03-01T06:42:44.007Z"
   },
   {
    "duration": 55,
    "start_time": "2022-03-01T06:42:45.077Z"
   },
   {
    "duration": 29,
    "start_time": "2022-03-01T06:42:45.134Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-01T06:42:45.165Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-01T06:42:45.170Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-01T06:42:45.193Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-01T06:42:45.201Z"
   },
   {
    "duration": 9173,
    "start_time": "2022-03-01T06:42:45.213Z"
   },
   {
    "duration": 8952,
    "start_time": "2022-03-01T06:42:54.387Z"
   },
   {
    "duration": 380,
    "start_time": "2022-03-01T07:09:38.372Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-01T07:10:40.192Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-01T07:10:46.315Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-01T07:10:58.104Z"
   },
   {
    "duration": 297,
    "start_time": "2022-03-01T07:11:32.882Z"
   },
   {
    "duration": 292470,
    "start_time": "2022-03-01T07:11:50.482Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-01T07:19:54.787Z"
   },
   {
    "duration": 118,
    "start_time": "2022-03-01T07:33:38.703Z"
   },
   {
    "duration": 286,
    "start_time": "2022-03-01T07:33:43.158Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-01T07:34:01.734Z"
   },
   {
    "duration": 337354,
    "start_time": "2022-03-01T07:43:59.650Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-01T07:50:01.151Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-01T07:51:42.222Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-01T08:44:46.002Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-01T08:44:55.748Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-01T08:45:12.684Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-01T08:45:39.499Z"
   },
   {
    "duration": 9074,
    "start_time": "2022-03-01T08:46:56.003Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-01T08:47:53.009Z"
   },
   {
    "duration": 8674,
    "start_time": "2022-03-01T08:48:13.545Z"
   },
   {
    "duration": 8697,
    "start_time": "2022-03-01T08:48:25.803Z"
   },
   {
    "duration": 336,
    "start_time": "2022-03-01T09:24:36.205Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-01T09:24:54.024Z"
   },
   {
    "duration": 2,
    "start_time": "2022-03-01T09:26:05.593Z"
   },
   {
    "duration": 306,
    "start_time": "2022-03-01T09:26:12.727Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-01T09:27:34.566Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-01T09:27:51.773Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-01T09:29:39.417Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-01T09:29:40.356Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-01T09:29:53.995Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-01T09:29:54.756Z"
   },
   {
    "duration": 2,
    "start_time": "2022-03-01T09:30:17.267Z"
   },
   {
    "duration": 2039,
    "start_time": "2022-03-01T09:30:17.963Z"
   },
   {
    "duration": 329,
    "start_time": "2022-03-01T09:30:46.835Z"
   },
   {
    "duration": 395,
    "start_time": "2022-03-01T09:32:14.578Z"
   },
   {
    "duration": 313,
    "start_time": "2022-03-01T09:33:53.392Z"
   },
   {
    "duration": 93,
    "start_time": "2022-03-01T09:35:30.526Z"
   },
   {
    "duration": 75,
    "start_time": "2022-03-01T09:39:00.480Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-01T10:07:36.681Z"
   },
   {
    "duration": 275,
    "start_time": "2022-03-01T11:09:36.600Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-01T11:09:45.112Z"
   },
   {
    "duration": 295,
    "start_time": "2022-03-01T11:12:13.894Z"
   },
   {
    "duration": 320,
    "start_time": "2022-03-01T11:12:25.413Z"
   },
   {
    "duration": 300,
    "start_time": "2022-03-01T11:12:40.278Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-01T11:15:31.939Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-01T11:16:20.000Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-01T11:17:07.818Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-01T11:20:02.878Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-01T11:21:16.238Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-01T11:21:24.194Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-01T11:22:52.980Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-01T11:24:51.226Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-01T11:27:59.776Z"
   },
   {
    "duration": 1062,
    "start_time": "2022-03-02T09:29:22.634Z"
   },
   {
    "duration": 56,
    "start_time": "2022-03-02T09:29:24.436Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-02T09:29:25.964Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-02T09:29:27.284Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-02T09:29:28.196Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-02T09:29:29.971Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-02T09:34:33.709Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-02T09:37:13.794Z"
   },
   {
    "duration": 9263,
    "start_time": "2022-03-02T09:37:16.517Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-02T09:37:32.492Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-02T09:37:33.396Z"
   },
   {
    "duration": 307895,
    "start_time": "2022-03-02T09:37:36.748Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-02T09:43:12.159Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-02T09:43:13.215Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-02T09:45:00.293Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-02T09:45:01.837Z"
   },
   {
    "duration": 101,
    "start_time": "2022-03-02T09:46:10.381Z"
   },
   {
    "duration": 112,
    "start_time": "2022-03-02T09:46:36.068Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-02T10:45:29.637Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-02T10:45:30.898Z"
   },
   {
    "duration": 395046,
    "start_time": "2022-03-02T10:45:32.898Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-02T10:52:15.501Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-02T10:52:16.909Z"
   },
   {
    "duration": 173,
    "start_time": "2022-03-02T10:53:21.069Z"
   },
   {
    "duration": 138,
    "start_time": "2022-03-02T10:54:32.572Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-02T10:55:01.961Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-02T10:55:02.579Z"
   },
   {
    "duration": 25792,
    "start_time": "2022-03-02T10:57:19.395Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-02T10:58:29.312Z"
   },
   {
    "duration": 106180,
    "start_time": "2022-03-02T11:07:11.561Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-02T11:14:58.027Z"
   },
   {
    "duration": 299,
    "start_time": "2022-03-02T11:17:52.746Z"
   },
   {
    "duration": 140,
    "start_time": "2022-03-02T11:18:00.770Z"
   },
   {
    "duration": 149,
    "start_time": "2022-03-02T11:18:31.217Z"
   },
   {
    "duration": 180,
    "start_time": "2022-03-02T11:19:33.313Z"
   },
   {
    "duration": 169,
    "start_time": "2022-03-02T11:20:11.583Z"
   },
   {
    "duration": 134,
    "start_time": "2022-03-02T11:20:37.599Z"
   },
   {
    "duration": 138,
    "start_time": "2022-03-02T11:20:44.143Z"
   },
   {
    "duration": 164,
    "start_time": "2022-03-02T11:20:48.711Z"
   },
   {
    "duration": 162,
    "start_time": "2022-03-02T11:20:53.022Z"
   },
   {
    "duration": 161,
    "start_time": "2022-03-02T11:20:56.559Z"
   },
   {
    "duration": 137,
    "start_time": "2022-03-02T11:21:05.103Z"
   },
   {
    "duration": 163,
    "start_time": "2022-03-02T11:21:26.703Z"
   },
   {
    "duration": 106506,
    "start_time": "2022-03-02T11:22:26.069Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-02T11:24:30.573Z"
   },
   {
    "duration": 144,
    "start_time": "2022-03-02T11:25:03.211Z"
   },
   {
    "duration": 166,
    "start_time": "2022-03-02T11:25:06.531Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-02T11:27:31.122Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-02T11:29:57.896Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-02T11:30:56.309Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-02T11:31:12.524Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-02T11:35:28.132Z"
   },
   {
    "duration": 225,
    "start_time": "2022-03-02T11:35:37.024Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-02T11:35:50.401Z"
   },
   {
    "duration": 1627,
    "start_time": "2022-03-03T12:43:55.368Z"
   },
   {
    "duration": 94,
    "start_time": "2022-03-03T12:43:56.998Z"
   },
   {
    "duration": 26,
    "start_time": "2022-03-03T12:43:57.095Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-03T12:43:57.124Z"
   },
   {
    "duration": 61,
    "start_time": "2022-03-03T12:43:57.132Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-03T12:43:57.196Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-03T12:43:57.212Z"
   },
   {
    "duration": 14597,
    "start_time": "2022-03-03T12:43:57.234Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-03T12:44:11.834Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-03T12:44:11.841Z"
   },
   {
    "duration": 601458,
    "start_time": "2022-03-03T12:44:11.851Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-03T12:54:13.312Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-03T12:54:13.331Z"
   },
   {
    "duration": 170954,
    "start_time": "2022-03-03T12:54:13.374Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-03T12:57:04.331Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-03T12:57:04.339Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-03T12:57:04.376Z"
   },
   {
    "duration": 231,
    "start_time": "2022-03-03T12:57:04.387Z"
   },
   {
    "duration": 260,
    "start_time": "2022-03-03T12:57:04.621Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-03T12:57:04.883Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-03T12:57:04.893Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-03T12:57:04.902Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "366.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
